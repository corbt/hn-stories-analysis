{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4920000, 12)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "\n",
    "df = pd.read_feather('/workspace/data/hn/stories_dump.feather')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126850, 12)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'descendants': 'comments'}, inplace=True)\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'], unit='s')\n",
    "df['dead'] = df.dead.fillna(0).astype(bool)\n",
    "\n",
    "# Keep stories from 2018 onward in case community tastes have changed\n",
    "df = df[df['time'].dt.year > 2017]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1810290, 12)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Only keep stories without text for now\n",
    "df = df[df['text'].isnull() & df['url'].notnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1544214, 12)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For this analysis we're trying to see whether a \"real\" story is likely to make\n",
    "# it to the front page. So let's remove dead stories as there are probably easier ways to detect those.\n",
    "df = df[df['dead'] == False]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1544214, 12)\n",
      "(1293918, 12)\n"
     ]
    }
   ],
   "source": [
    "# Deduplicate stories based on the URL. Keep the one with the highest score.\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "df.sort_values(by=['score'], ascending=False, inplace=True)\n",
    "df = df.drop_duplicates(subset=['url'], keep='first')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['frontpage'] = (df.score >= 20) | (df.comments >= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['by', 'comments', 'id', 'score', 'time', 'title', 'type', 'url', 'dead',\n",
       "       'text', 'kids', 'deleted', 'frontpage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6528b31608834a1780aae574b094c64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/1293918 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def format_text(row):\n",
    "  return f\"\"\"Title: {row.title}\n",
    "URL: {row.url}\n",
    "Poster: {row.by}\n",
    "Date: {row.time.strftime('%A, %B %d, %I:%M %p')}\"\"\"\n",
    "\n",
    "df['formatted_text'] = df.swifter.apply(format_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: How to set junior employees up for success in remote\n",
      "URL: https://slite.com/blog/micromanagement-is-not-a-bad-word\n",
      "Poster: melanieb421\n",
      "Date: Monday, June 27, 12:10 PM\n",
      "\n",
      "Title: Sewage Is Helping Cities Flush Out the Opioid Crisis\n",
      "URL: https://www.scientificamerican.com/article/sewage-is-helping-cities-flush-out-the-opioid-crisis/\n",
      "Poster: dustfinger\n",
      "Date: Monday, May 28, 10:24 AM\n",
      "\n",
      "Title: Raspberry Pi Zero W Surveillance Camera\n",
      "URL: https://www.youtube.com/watch?v=rhIzfRmKHnQ\n",
      "Poster: fortran77\n",
      "Date: Friday, June 05, 04:57 PM\n",
      "\n",
      "Title: Date World: The Army’s Authoritative Training Environment\n",
      "URL: https://www.army.mil/article/242997/decisive_action_training_environment_world_the_armys_authoritative_training_environment\n",
      "Poster: openasocket\n",
      "Date: Wednesday, April 14, 06:33 PM\n",
      "\n",
      "Title: SQL 3D engine (interactive preview)\n",
      "URL: https://observablehq.com/@pallada-92/sql-3d-engine\n",
      "Poster: duck\n",
      "Date: Thursday, February 27, 09:59 PM\n",
      "\n",
      "Title: How do you explain technical subjects in a non condescending way to senior?\n",
      "URL: https://workplace.stackexchange.com/questions/188706/how-do-you-explain-highly-technical-subjects-in-a-non-condescending-way-to-senio\n",
      "Poster: nsoonhui\n",
      "Date: Friday, November 25, 07:30 AM\n",
      "\n",
      "Title: C.uk\n",
      "URL: http://www.c.uk/\n",
      "Poster: logikblok\n",
      "Date: Sunday, April 09, 04:20 PM\n",
      "\n",
      "Title: Air Jordan 1 Low OG “Atmosphere Grey” Releasing September 2023\n",
      "URL: https://sneakerbardetroit.com/air-jordan-1-low-og-atmosphere-grey-cz0790-101-release-date/\n",
      "Poster: trifit\n",
      "Date: Saturday, January 14, 12:56 PM\n",
      "\n",
      "Title: Facebook Brexit ads secretly run by staff of lobbying company\n",
      "URL: https://www.theguardian.com/politics/2019/apr/03/grassroots-facebook-brexit-ads-secretly-run-by-staff-of-lynton-crosby-firm\n",
      "Poster: privateprofile\n",
      "Date: Wednesday, April 03, 04:12 PM\n",
      "\n",
      "Title: TiKV Performance Tuning with Regions\n",
      "URL: https://tikv.org/blog/tune-with-massive-regions-in-tikv/\n",
      "Poster: WTTT\n",
      "Date: Monday, June 15, 12:22 AM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print 10 random stories\n",
    "for i, row in df.sample(10).iterrows():\n",
    "  print(row.formatted_text)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfab01d55f7b47638fc6c4ab040ed39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['by', 'comments', 'id', 'score', 'time', 'title', 'type', 'url', 'dead',\n",
       "       'text', 'kids', 'deleted', 'frontpage', 'formatted_text', 'input_ids',\n",
       "       'token_type_ids', 'attention_mask'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    tokenizer_columns = tokenizer(chunk['formatted_text'].tolist(), padding=False, truncation=True, max_length=512)\n",
    "    for key in tokenizer_columns:\n",
    "        chunk[key] = tokenizer_columns[key]\n",
    "    return chunk\n",
    "\n",
    "# Split the dataset into batches of 1000 and apply the tokenizer columns to each batch\n",
    "chunks = np.array_split(df, ceil(df.shape[0]/1000))\n",
    "\n",
    "df = pd.concat([process_chunk(chunk) for chunk in tqdm(chunks)])\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "test       64728\n",
       "train    1229190\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign 5% of the data to the test set randomly\n",
    "df['split'] = np.random.choice(['train', 'test'], p=[0.95, 0.05], size=(df.shape[0],))\n",
    "df = df.sample(frac=1, random_state=1318)\n",
    "\n",
    "df.groupby('split').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'time', 'input_ids', 'attention_mask', 'labels'], dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels need to be a float for RMSE calculation\n",
    "df['labels'] = df['frontpage'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True).to_feather('/workspace/data/hn/stories-dataset.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels', 'split'],\n",
       "        num_rows: 1229190\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'input_ids', 'attention_mask', 'labels', 'split'],\n",
       "        num_rows: 64728\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "df = pd.read_feather('/workspace/data/hn/stories-dataset.feather')\n",
    "\n",
    "# Get just the columns we need\n",
    "df = df[['id', 'input_ids', 'attention_mask', 'labels', 'split']]\n",
    "\n",
    "dataset = DatasetDict({\n",
    "  'train': Dataset.from_pandas(df[df['split'] == 'train'], preserve_index=False),\n",
    "  'test': Dataset.from_pandas(df[df['split'] == 'test'], preserve_index=False)\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bea077df3ff479f991ba7014554131b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/3 shards):   0%|          | 0/1229190 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc58dd721b54da6a56e0ac49c72efa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/64728 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.save_to_disk('/workspace/data/hn/stories-dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
