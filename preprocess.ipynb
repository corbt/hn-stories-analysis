{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.24.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.65.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install zstandard pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed 100000 lines (2%) (0 failed)\n",
      "Processed 100000 lines (2%) (0 failed)\n",
      "Processed 100000 lines (2%) (0 failed)\n",
      "Processed 100000 lines (2%) (0 failed)\n",
      "Processed 100000 lines (2%) (0 failed)\n",
      "Processed 100000 lines (2%) (0 failed)\n",
      "Processed 200000 lines (3%) (0 failed)\n",
      "Processed 200000 lines (3%) (0 failed)\n",
      "Processed 200000 lines (3%) (0 failed)\n",
      "Processed 200000 lines (3%) (0 failed)\n",
      "Processed 200000 lines (3%) (0 failed)\n",
      "Processed 200000 lines (3%) (0 failed)\n",
      "Processed 300000 lines (5%) (0 failed)\n",
      "Processed 300000 lines (5%) (0 failed)\n",
      "Processed 300000 lines (5%) (0 failed)\n",
      "Processed 300000 lines (5%) (0 failed)\n",
      "Processed 300000 lines (5%) (0 failed)\n",
      "Processed 300000 lines (5%) (0 failed)\n",
      "Processed 400000 lines (6%) (0 failed)\n",
      "Processed 400000 lines (6%) (0 failed)\n",
      "Processed 400000 lines (6%) (0 failed)\n",
      "Processed 400000 lines (6%) (0 failed)\n",
      "Processed 400000 lines (6%) (0 failed)\n",
      "Processed 400000 lines (6%) (0 failed)\n",
      "Processed 500000 lines (8%) (0 failed)\n",
      "Processed 500000 lines (8%) (0 failed)\n",
      "Processed 500000 lines (8%) (0 failed)\n",
      "Processed 500000 lines (8%) (0 failed)\n",
      "Processed 500000 lines (8%) (0 failed)\n",
      "Processed 500000 lines (8%) (0 failed)\n",
      "Processed 600000 lines (9%) (0 failed)\n",
      "Processed 600000 lines (9%) (0 failed)\n",
      "Processed 600000 lines (9%) (0 failed)\n",
      "Processed 600000 lines (9%) (0 failed)\n",
      "Processed 600000 lines (9%) (0 failed)\n",
      "Processed 600000 lines (9%) (0 failed)\n",
      "Processed 700000 lines (11%) (0 failed)\n",
      "Processed 700000 lines (11%) (0 failed)\n",
      "Processed 700000 lines (11%) (0 failed)\n",
      "Processed 700000 lines (11%) (0 failed)\n",
      "Processed 700000 lines (11%) (0 failed)\n",
      "Processed 700000 lines (11%) (0 failed)\n",
      "Processed 800000 lines (13%) (0 failed)\n",
      "Processed 800000 lines (13%) (0 failed)\n",
      "Processed 800000 lines (13%) (0 failed)\n",
      "Processed 800000 lines (13%) (0 failed)\n",
      "Processed 800000 lines (13%) (0 failed)\n",
      "Processed 800000 lines (13%) (0 failed)\n",
      "Processed 900000 lines (14%) (0 failed)\n",
      "Processed 900000 lines (14%) (0 failed)\n",
      "Processed 900000 lines (14%) (0 failed)\n",
      "Processed 900000 lines (14%) (0 failed)\n",
      "Processed 900000 lines (14%) (0 failed)\n",
      "Processed 900000 lines (14%) (0 failed)\n",
      "Processed 1000000 lines (16%) (0 failed)\n",
      "Processed 1000000 lines (16%) (0 failed)\n",
      "Processed 1000000 lines (16%) (0 failed)\n",
      "Processed 1000000 lines (16%) (0 failed)\n",
      "Processed 1000000 lines (16%) (0 failed)\n",
      "Processed 1000000 lines (16%) (0 failed)\n",
      "Processed 1100000 lines (18%) (0 failed)\n",
      "Processed 1100000 lines (18%) (0 failed)\n",
      "Processed 1100000 lines (18%) (0 failed)\n",
      "Processed 1100000 lines (18%) (0 failed)\n",
      "Processed 1100000 lines (18%) (0 failed)\n",
      "Processed 1100000 lines (18%) (0 failed)\n",
      "Processed 1200000 lines (19%) (0 failed)\n",
      "Processed 1200000 lines (19%) (0 failed)\n",
      "Processed 1200000 lines (19%) (0 failed)\n",
      "Processed 1200000 lines (19%) (0 failed)\n",
      "Processed 1200000 lines (19%) (0 failed)\n",
      "Processed 1200000 lines (19%) (0 failed)\n",
      "Processed 1300000 lines (21%) (0 failed)\n",
      "Processed 1300000 lines (21%) (0 failed)\n",
      "Processed 1300000 lines (21%) (0 failed)\n",
      "Processed 1300000 lines (21%) (0 failed)\n",
      "Processed 1300000 lines (21%) (0 failed)\n",
      "Processed 1300000 lines (21%) (0 failed)\n",
      "Processed 1400000 lines (23%) (0 failed)\n",
      "Processed 1400000 lines (23%) (0 failed)\n",
      "Processed 1400000 lines (23%) (0 failed)\n",
      "Processed 1400000 lines (23%) (0 failed)\n",
      "Processed 1400000 lines (23%) (0 failed)\n",
      "Processed 1400000 lines (23%) (0 failed)\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Processed 1500000 lines (24%) (0 failed)\n",
      "Processed 1500000 lines (24%) (0 failed)\n",
      "Processed 1500000 lines (24%) (0 failed)\n",
      "Processed 1500000 lines (24%) (0 failed)\n",
      "Processed 1500000 lines (24%) (0 failed)\n",
      "Processed 1500000 lines (24%) (0 failed)\n",
      "Processed 1600000 lines (26%) (0 failed)\n",
      "Processed 1600000 lines (26%) (0 failed)\n",
      "Processed 1600000 lines (26%) (0 failed)\n",
      "Processed 1600000 lines (26%) (0 failed)\n",
      "Processed 1600000 lines (26%) (0 failed)\n",
      "Processed 1600000 lines (26%) (0 failed)\n",
      "Processed 1700000 lines (28%) (0 failed)\n",
      "Processed 1700000 lines (28%) (0 failed)\n",
      "Processed 1700000 lines (28%) (0 failed)\n",
      "Processed 1700000 lines (28%) (0 failed)\n",
      "Processed 1700000 lines (28%) (0 failed)\n",
      "Processed 1700000 lines (28%) (0 failed)\n",
      "Processed 1800000 lines (29%) (0 failed)\n",
      "Processed 1800000 lines (29%) (0 failed)\n",
      "Processed 1800000 lines (29%) (0 failed)\n",
      "Processed 1800000 lines (29%) (0 failed)\n",
      "Processed 1800000 lines (29%) (0 failed)\n",
      "Processed 1800000 lines (29%) (0 failed)\n",
      "Processed 1900000 lines (31%) (0 failed)\n",
      "Processed 1900000 lines (31%) (0 failed)\n",
      "Processed 1900000 lines (31%) (0 failed)\n",
      "Processed 1900000 lines (31%) (0 failed)\n",
      "Processed 1900000 lines (31%) (0 failed)\n",
      "Processed 1900000 lines (31%) (0 failed)\n",
      "Processed 2000000 lines (33%) (0 failed)\n",
      "Processed 2000000 lines (33%) (0 failed)\n",
      "Processed 2000000 lines (33%) (0 failed)\n",
      "Processed 2000000 lines (33%) (0 failed)\n",
      "Processed 2000000 lines (33%) (0 failed)\n",
      "Processed 2000000 lines (33%) (0 failed)\n",
      "Processed 2100000 lines (34%) (0 failed)\n",
      "Processed 2100000 lines (34%) (0 failed)\n",
      "Processed 2100000 lines (34%) (0 failed)\n",
      "Processed 2100000 lines (34%) (0 failed)\n",
      "Processed 2100000 lines (34%) (0 failed)\n",
      "Processed 2100000 lines (34%) (0 failed)\n",
      "Processed 2200000 lines (36%) (0 failed)\n",
      "Processed 2200000 lines (36%) (0 failed)\n",
      "Processed 2200000 lines (36%) (0 failed)\n",
      "Processed 2200000 lines (36%) (0 failed)\n",
      "Processed 2200000 lines (36%) (0 failed)\n",
      "Processed 2200000 lines (36%) (0 failed)\n",
      "Processed 2300000 lines (38%) (0 failed)\n",
      "Processed 2300000 lines (38%) (0 failed)\n",
      "Processed 2300000 lines (38%) (0 failed)\n",
      "Processed 2300000 lines (38%) (0 failed)\n",
      "Processed 2300000 lines (38%) (0 failed)\n",
      "Processed 2300000 lines (38%) (0 failed)\n",
      "Processed 2400000 lines (39%) (0 failed)\n",
      "Processed 2400000 lines (39%) (0 failed)\n",
      "Processed 2400000 lines (39%) (0 failed)\n",
      "Processed 2400000 lines (39%) (0 failed)\n",
      "Processed 2400000 lines (39%) (0 failed)\n",
      "Processed 2400000 lines (39%) (0 failed)\n",
      "Processed 2500000 lines (41%) (0 failed)\n",
      "Processed 2500000 lines (41%) (0 failed)\n",
      "Processed 2500000 lines (41%) (0 failed)\n",
      "Processed 2500000 lines (41%) (0 failed)\n",
      "Processed 2500000 lines (41%) (0 failed)\n",
      "Processed 2500000 lines (41%) (0 failed)\n",
      "Processed 2600000 lines (43%) (0 failed)\n",
      "Processed 2600000 lines (43%) (0 failed)\n",
      "Processed 2600000 lines (43%) (0 failed)\n",
      "Processed 2600000 lines (43%) (0 failed)\n",
      "Processed 2600000 lines (43%) (0 failed)\n",
      "Processed 2600000 lines (43%) (0 failed)\n",
      "Processed 2700000 lines (44%) (0 failed)\n",
      "Processed 2700000 lines (44%) (0 failed)\n",
      "Processed 2700000 lines (44%) (0 failed)\n",
      "Processed 2700000 lines (44%) (0 failed)\n",
      "Processed 2700000 lines (44%) (0 failed)\n",
      "Processed 2700000 lines (44%) (0 failed)\n",
      "Processed 2800000 lines (46%) (0 failed)\n",
      "Processed 2800000 lines (46%) (0 failed)\n",
      "Processed 2800000 lines (46%) (0 failed)\n",
      "Processed 2800000 lines (46%) (0 failed)\n",
      "Processed 2800000 lines (46%) (0 failed)\n",
      "Processed 2800000 lines (46%) (0 failed)\n",
      "Processed 2900000 lines (48%) (0 failed)\n",
      "Processed 2900000 lines (48%) (0 failed)\n",
      "Processed 2900000 lines (48%) (0 failed)\n",
      "Processed 2900000 lines (48%) (0 failed)\n",
      "Processed 2900000 lines (48%) (0 failed)\n",
      "Processed 2900000 lines (48%) (0 failed)\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Processed 3000000 lines (50%) (0 failed)\n",
      "Processed 3000000 lines (50%) (0 failed)\n",
      "Processed 3000000 lines (50%) (0 failed)\n",
      "Processed 3000000 lines (50%) (0 failed)\n",
      "Processed 3000000 lines (50%) (0 failed)\n",
      "Processed 3000000 lines (50%) (0 failed)\n",
      "Processed 3100000 lines (51%) (0 failed)\n",
      "Processed 3100000 lines (51%) (0 failed)\n",
      "Processed 3100000 lines (51%) (0 failed)\n",
      "Processed 3100000 lines (51%) (0 failed)\n",
      "Processed 3100000 lines (51%) (0 failed)\n",
      "Processed 3100000 lines (51%) (0 failed)\n",
      "Processed 3200000 lines (53%) (0 failed)\n",
      "Processed 3200000 lines (53%) (0 failed)\n",
      "Processed 3200000 lines (53%) (0 failed)\n",
      "Processed 3200000 lines (53%) (0 failed)\n",
      "Processed 3200000 lines (53%) (0 failed)\n",
      "Processed 3200000 lines (53%) (0 failed)\n",
      "Processed 3300000 lines (55%) (0 failed)\n",
      "Processed 3300000 lines (55%) (0 failed)\n",
      "Processed 3300000 lines (55%) (0 failed)\n",
      "Processed 3300000 lines (55%) (0 failed)\n",
      "Processed 3300000 lines (55%) (0 failed)\n",
      "Processed 3300000 lines (55%) (0 failed)\n",
      "Processed 3400000 lines (56%) (0 failed)\n",
      "Processed 3400000 lines (56%) (0 failed)\n",
      "Processed 3400000 lines (56%) (0 failed)\n",
      "Processed 3400000 lines (56%) (0 failed)\n",
      "Processed 3400000 lines (56%) (0 failed)\n",
      "Processed 3400000 lines (56%) (0 failed)\n",
      "Processed 3500000 lines (58%) (0 failed)\n",
      "Processed 3500000 lines (58%) (0 failed)\n",
      "Processed 3500000 lines (58%) (0 failed)\n",
      "Processed 3500000 lines (58%) (0 failed)\n",
      "Processed 3500000 lines (58%) (0 failed)\n",
      "Processed 3500000 lines (58%) (0 failed)\n",
      "Processed 3600000 lines (60%) (0 failed)\n",
      "Processed 3600000 lines (60%) (0 failed)\n",
      "Processed 3600000 lines (60%) (0 failed)\n",
      "Processed 3600000 lines (60%) (0 failed)\n",
      "Processed 3600000 lines (60%) (0 failed)\n",
      "Processed 3600000 lines (60%) (0 failed)\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Processed 3700000 lines (61%) (0 failed)\n",
      "Processed 3700000 lines (61%) (0 failed)\n",
      "Processed 3700000 lines (61%) (0 failed)\n",
      "Processed 3700000 lines (61%) (0 failed)\n",
      "Processed 3700000 lines (61%) (0 failed)\n",
      "Processed 3700000 lines (61%) (0 failed)\n",
      "Processed 3800000 lines (63%) (0 failed)\n",
      "Processed 3800000 lines (63%) (0 failed)\n",
      "Processed 3800000 lines (63%) (0 failed)\n",
      "Processed 3800000 lines (63%) (0 failed)\n",
      "Processed 3800000 lines (63%) (0 failed)\n",
      "Processed 3800000 lines (63%) (0 failed)\n",
      "Processed 3900000 lines (65%) (0 failed)\n",
      "Processed 3900000 lines (65%) (0 failed)\n",
      "Processed 3900000 lines (65%) (0 failed)\n",
      "Processed 3900000 lines (65%) (0 failed)\n",
      "Processed 3900000 lines (65%) (0 failed)\n",
      "Processed 3900000 lines (65%) (0 failed)\n",
      "Processed 4000000 lines (66%) (0 failed)\n",
      "Processed 4000000 lines (66%) (0 failed)\n",
      "Processed 4000000 lines (66%) (0 failed)\n",
      "Processed 4000000 lines (66%) (0 failed)\n",
      "Processed 4000000 lines (66%) (0 failed)\n",
      "Processed 4000000 lines (66%) (0 failed)\n",
      "Processed 4100000 lines (68%) (0 failed)\n",
      "Processed 4100000 lines (68%) (0 failed)\n",
      "Processed 4100000 lines (68%) (0 failed)\n",
      "Processed 4100000 lines (68%) (0 failed)\n",
      "Processed 4100000 lines (68%) (0 failed)\n",
      "Processed 4100000 lines (68%) (0 failed)\n",
      "Processed 4200000 lines (70%) (0 failed)\n",
      "Processed 4200000 lines (70%) (0 failed)\n",
      "Processed 4200000 lines (70%) (0 failed)\n",
      "Processed 4200000 lines (70%) (0 failed)\n",
      "Processed 4200000 lines (70%) (0 failed)\n",
      "Processed 4200000 lines (70%) (0 failed)\n",
      "Processed 4300000 lines (71%) (0 failed)\n",
      "Processed 4300000 lines (71%) (0 failed)\n",
      "Processed 4300000 lines (71%) (0 failed)\n",
      "Processed 4300000 lines (71%) (0 failed)\n",
      "Processed 4300000 lines (71%) (0 failed)\n",
      "Processed 4300000 lines (71%) (0 failed)\n",
      "Processed 4400000 lines (73%) (0 failed)\n",
      "Processed 4400000 lines (73%) (0 failed)\n",
      "Processed 4400000 lines (73%) (0 failed)\n",
      "Processed 4400000 lines (73%) (0 failed)\n",
      "Processed 4400000 lines (73%) (0 failed)\n",
      "Processed 4400000 lines (73%) (0 failed)\n",
      "Processed 4500000 lines (75%) (0 failed)\n",
      "Processed 4500000 lines (75%) (0 failed)\n",
      "Processed 4500000 lines (75%) (0 failed)\n",
      "Processed 4500000 lines (75%) (0 failed)\n",
      "Processed 4500000 lines (75%) (0 failed)\n",
      "Processed 4500000 lines (75%) (0 failed)\n",
      "Processed 4600000 lines (76%) (0 failed)\n",
      "Processed 4600000 lines (76%) (0 failed)\n",
      "Processed 4600000 lines (76%) (0 failed)\n",
      "Processed 4600000 lines (76%) (0 failed)\n",
      "Processed 4600000 lines (76%) (0 failed)\n",
      "Processed 4600000 lines (76%) (0 failed)\n",
      "Processed 4700000 lines (78%) (0 failed)\n",
      "Processed 4700000 lines (78%) (0 failed)\n",
      "Processed 4700000 lines (78%) (0 failed)\n",
      "Processed 4700000 lines (78%) (0 failed)\n",
      "Processed 4700000 lines (78%) (0 failed)\n",
      "Processed 4700000 lines (78%) (0 failed)\n",
      "Processed 4800000 lines (79%) (0 failed)\n",
      "Processed 4800000 lines (79%) (0 failed)\n",
      "Processed 4800000 lines (79%) (0 failed)\n",
      "Processed 4800000 lines (79%) (0 failed)\n",
      "Processed 4800000 lines (79%) (0 failed)\n",
      "Processed 4800000 lines (79%) (0 failed)\n",
      "Processed 4900000 lines (81%) (0 failed)\n",
      "Processed 4900000 lines (81%) (0 failed)\n",
      "Processed 4900000 lines (81%) (0 failed)\n",
      "Processed 4900000 lines (81%) (0 failed)\n",
      "Processed 4900000 lines (81%) (0 failed)\n",
      "Processed 4900000 lines (81%) (0 failed)\n",
      "Processed 5000000 lines (83%) (0 failed)\n",
      "Processed 5000000 lines (83%) (0 failed)\n",
      "Processed 5000000 lines (83%) (0 failed)\n",
      "Processed 5000000 lines (83%) (0 failed)\n",
      "Processed 5000000 lines (83%) (0 failed)\n",
      "Processed 5000000 lines (83%) (0 failed)\n",
      "Processed 5100000 lines (84%) (0 failed)\n",
      "Processed 5100000 lines (84%) (0 failed)\n",
      "Processed 5100000 lines (84%) (0 failed)\n",
      "Processed 5100000 lines (84%) (0 failed)\n",
      "Processed 5100000 lines (84%) (0 failed)\n",
      "Processed 5100000 lines (84%) (0 failed)\n",
      "Processed 5200000 lines (86%) (0 failed)\n",
      "Processed 5200000 lines (86%) (0 failed)\n",
      "Processed 5200000 lines (86%) (0 failed)\n",
      "Processed 5200000 lines (86%) (0 failed)\n",
      "Processed 5200000 lines (86%) (0 failed)\n",
      "Processed 5200000 lines (86%) (0 failed)\n",
      "Processed 5300000 lines (87%) (0 failed)\n",
      "Processed 5300000 lines (87%) (0 failed)\n",
      "Processed 5300000 lines (87%) (0 failed)\n",
      "Processed 5300000 lines (87%) (0 failed)\n",
      "Processed 5300000 lines (87%) (0 failed)\n",
      "Processed 5300000 lines (87%) (0 failed)\n",
      "Processed 5400000 lines (89%) (0 failed)\n",
      "Processed 5400000 lines (89%) (0 failed)\n",
      "Processed 5400000 lines (89%) (0 failed)\n",
      "Processed 5400000 lines (89%) (0 failed)\n",
      "Processed 5400000 lines (89%) (0 failed)\n",
      "Processed 5400000 lines (89%) (0 failed)\n",
      "Processed 5500000 lines (91%) (0 failed)\n",
      "Processed 5500000 lines (91%) (0 failed)\n",
      "Processed 5500000 lines (91%) (0 failed)\n",
      "Processed 5500000 lines (91%) (0 failed)\n",
      "Processed 5500000 lines (91%) (0 failed)\n",
      "Processed 5500000 lines (91%) (0 failed)\n",
      "Processed 5600000 lines (92%) (0 failed)\n",
      "Processed 5600000 lines (92%) (0 failed)\n",
      "Processed 5600000 lines (92%) (0 failed)\n",
      "Processed 5600000 lines (92%) (0 failed)\n",
      "Processed 5600000 lines (92%) (0 failed)\n",
      "Processed 5600000 lines (92%) (0 failed)\n",
      "Processed 5700000 lines (94%) (0 failed)\n",
      "Processed 5700000 lines (94%) (0 failed)\n",
      "Processed 5700000 lines (94%) (0 failed)\n",
      "Processed 5700000 lines (94%) (0 failed)\n",
      "Processed 5700000 lines (94%) (0 failed)\n",
      "Processed 5700000 lines (94%) (0 failed)\n",
      "Processed 5800000 lines (96%) (0 failed)\n",
      "Processed 5800000 lines (96%) (0 failed)\n",
      "Processed 5800000 lines (96%) (0 failed)\n",
      "Processed 5800000 lines (96%) (0 failed)\n",
      "Processed 5800000 lines (96%) (0 failed)\n",
      "Processed 5800000 lines (96%) (0 failed)\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Processed 5900000 lines (97%) (0 failed)\n",
      "Processed 5900000 lines (97%) (0 failed)\n",
      "Processed 5900000 lines (97%) (0 failed)\n",
      "Processed 5900000 lines (97%) (0 failed)\n",
      "Processed 5900000 lines (97%) (0 failed)\n",
      "Processed 5900000 lines (97%) (0 failed)\n",
      "Processed 6000000 lines (99%) (0 failed)\n",
      "Processed 6000000 lines (99%) (0 failed)\n",
      "Processed 6000000 lines (99%) (0 failed)\n",
      "Processed 6000000 lines (99%) (0 failed)\n",
      "Processed 6000000 lines (99%) (0 failed)\n",
      "Processed 6000000 lines (99%) (0 failed)\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Decoding error with 134,217,728 bytes, reading another chunk\n",
      "Complete : 6,075,453 : 0\n",
      "Complete : 6,075,453 : 0\n",
      "Complete : 6,075,453 : 0\n",
      "Complete : 6,075,453 : 0\n",
      "Complete : 6,075,453 : 0\n",
      "Complete : 6,075,453 : 0\n"
     ]
    }
   ],
   "source": [
    "# Adapted from https://github.com/Watchful1/PushshiftDumps/blob/master/scripts/single_file.py\n",
    "\n",
    "import zstandard\n",
    "import os\n",
    "import json\n",
    "import logging.handlers\n",
    "\n",
    "\n",
    "log = logging.getLogger(\"bot\")\n",
    "log.setLevel(logging.DEBUG)\n",
    "log.addHandler(logging.StreamHandler())\n",
    "\n",
    "def read_and_decode(reader, chunk_size, max_window_size, previous_chunk=None, bytes_read=0):\n",
    "\tchunk = reader.read(chunk_size)\n",
    "\tbytes_read += chunk_size\n",
    "\tif previous_chunk is not None:\n",
    "\t\tchunk = previous_chunk + chunk\n",
    "\ttry:\n",
    "\t\treturn chunk.decode()\n",
    "\texcept UnicodeDecodeError:\n",
    "\t\tif bytes_read > max_window_size:\n",
    "\t\t\traise UnicodeError(f\"Unable to decode frame after reading {bytes_read:,} bytes\")\n",
    "\t\tlog.info(f\"Decoding error with {bytes_read:,} bytes, reading another chunk\")\n",
    "\t\treturn read_and_decode(reader, chunk_size, max_window_size, chunk, bytes_read)\n",
    "\n",
    "\n",
    "def read_lines_zst(file_name):\n",
    "\twith open(file_name, 'rb') as file_handle:\n",
    "\t\tbuffer = ''\n",
    "\t\treader = zstandard.ZstdDecompressor(max_window_size=2**31).stream_reader(file_handle)\n",
    "\t\twhile True:\n",
    "\t\t\tchunk = read_and_decode(reader, 2**27, (2**29) * 2)\n",
    "\n",
    "\t\t\tif not chunk:\n",
    "\t\t\t\tbreak\n",
    "\t\t\tlines = (buffer + chunk).split(\"\\n\")\n",
    "\n",
    "\t\t\tfor line in lines[:-1]:\n",
    "\t\t\t\tyield line, file_handle.tell()\n",
    "\n",
    "\t\t\tbuffer = lines[-1]\n",
    "\n",
    "\t\treader.close()\n",
    "\n",
    "\n",
    "in_file = '/workspace/data/reddit/submissions/RS_2023-01.zst'\n",
    "out_file = '/workspace/data/reddit/submissions/RS_2023-01.jsonl'\n",
    "\n",
    "fields = [\n",
    "  'id',\n",
    "  'author',\n",
    "  'subreddit',\n",
    "  'title',\n",
    "  'selftext',\n",
    "  'created_utc',\n",
    "  'score',\n",
    "  'upvote_ratio',\n",
    "  'removed_by_category',\n",
    "  'num_comments',\n",
    "]\n",
    "\n",
    "file_size = os.stat(in_file).st_size\n",
    "file_lines = 0\n",
    "file_bytes_processed = 0\n",
    "created = None\n",
    "bad_lines = 0\n",
    "\n",
    "with open(out_file, 'w') as out:\n",
    "  for line, file_bytes_processed in read_lines_zst(in_file):    \n",
    "    file_lines += 1\n",
    "    if file_lines % 100000 == 0:\n",
    "      log.info(f\"Processed {file_lines} lines ({(file_bytes_processed / file_size) * 100:.0f}%) ({bad_lines} failed)\")\n",
    "\n",
    "    try:\n",
    "      parsed = json.loads(line)\n",
    "\n",
    "      if len(parsed['selftext'] or '') < 10:\n",
    "        continue\n",
    "      \n",
    "      # Only keep the fields we want\n",
    "      obj = {k: parsed[k] for k in fields}\n",
    "      \n",
    "      out.write(json.dumps(obj) + '\\n')\n",
    "    except (KeyError, json.JSONDecodeError) as err:\n",
    "      print(err)\n",
    "\n",
    "log.info(f\"Complete : {file_lines:,} : {bad_lines:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(out_file, lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subreddit'] = df['subreddit'].astype('category')\n",
    "\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_feather('/workspace/data/reddit/submissions/RS_2023-01.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_feather('/workspace/data/reddit/submissions/RS_2023-01.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to only subreddits with at least 1000 submissions\n",
    "df = df.groupby('subreddit').filter(lambda x: len(x) > 1000)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log_score'] = np.log10(df['score'] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2380634/2380634 [03:23<00:00, 11700.96it/s]\n"
     ]
    }
   ],
   "source": [
    "def format_text(row):\n",
    "  return f\"\"\"Title: {row.title}\n",
    "Subreddit: /r/{row.subreddit}\n",
    "Author: /u/{row.author}\n",
    "Posted: {row.created_utc.strftime('%A, %B %d, %I:%M %p')}\n",
    "\n",
    "Text: {row.selftext}\"\"\"\n",
    "\n",
    "df['formatted_text'] = df.progress_apply(format_text, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1904507, 11), (476127, 11))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and test based on date. 80% train, 20% test\n",
    "\n",
    "df = df.sort_values('created_utc')\n",
    "\n",
    "split_date = df.iloc[int(len(df) * 0.8)]['created_utc']\n",
    "\n",
    "train_df = df[df['created_utc'] < split_date]\n",
    "test_df = df[df['created_utc'] >= split_date]\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.reset_index(drop=True).to_feather('/workspace/data/reddit/submissions/RS_2023-01-train.arrow')\n",
    "test_df.reset_index(drop=True).to_feather('/workspace/data/reddit/submissions/RS_2023-01-test.arrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
